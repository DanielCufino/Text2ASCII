{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c1KCk8E9x8",
        "outputId": "291eba5e-6192-4284-9773-3a87778d3de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esabEm6KYs2b",
        "outputId": "459241c6-7307-45af-d375-997d9ce6f619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (4.26.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: filelock in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8w33ZvtYs2d",
        "outputId": "f772526e-2c00-45e4-fee3-4d4c329cc121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /Users/danielcufino/miniforge3/envs/torch/lib/python3.8/site-packages (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LyBR5ZncYs2e"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYBRx8i8Ys2d",
        "outputId": "fe65e751-6c8f-4ce2-c9e5-de3c32011d00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.24.0\n",
            "1.13.0.dev20220619\n"
          ]
        }
      ],
      "source": [
        "print(transformers.__version__)\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0QmqkXu2Ys2e",
        "outputId": "2d82078a-3940-44b3-c7e9-78bc63ffeda4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mps'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5VaTradYs2e"
      },
      "source": [
        "# Define our Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6tcNyi99Ys2f"
      },
      "outputs": [],
      "source": [
        "class ASCIIDataset(Dataset):\n",
        "    def __init__(self, path, tokenizer):\n",
        "        '''\n",
        "            Path: string of the path to the raw data to convert to a dataset.\n",
        "\n",
        "                The path should a contain a file formatted as an array of JSON objects where the object is of the form:\n",
        "                    {\n",
        "                        \"prompt\": \"...\",\n",
        "                        \"text\": \"...\"\n",
        "                    }\n",
        "\n",
        "            Tokenizer:\n",
        "\n",
        "                The tokenizer used on the prompts and responses of the dataset. Should be GPT2 pre-trained tokenizer.\n",
        "        '''\n",
        "        self.data = None\n",
        "        self.X = []\n",
        "        self.tokenizer = tokenizer\n",
        "        # ID OF THE TOKEN USED TO INDICATE WHEN A RESPONSE BEGINS\n",
        "        self.res_id = 50260 # = self.decode_str(\"<RES>:\")\n",
        "\n",
        "\n",
        "        with open(path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "            # for entry in self.data[:100]:\n",
        "            #     prompt = entry['prompt'] \n",
        "            #     text = entry['text']\n",
        "            #     self.X.append(f'<BOS> {prompt}\\n<RES>:\\n{text}\\n<EOS>')\n",
        "\n",
        "            # For now just train on the first image repeatedly to see if it can learn on it\n",
        "            for entry in self.data[:1]:\n",
        "                prompt = entry['prompt'] \n",
        "                text = entry['text']\n",
        "                self.X.append(f'<BOS> {prompt}\\n<RES>:\\n{text}\\n<EOS>')\n",
        "            for _ in range(99):\n",
        "                self.X.append(self.X[0])\n",
        "            # print(test[0])\n",
        "\n",
        "        # for entry in self.data:\n",
        "        #     prompt = entry['prompt']\n",
        "        #     text = entry['text']\n",
        "        #     self.X.append(f'<BOS> {prompt} <bot>: {text} <EOS>')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        print(\"Tokenizing Text...\")\n",
        "        self.X_encoded = self.tokenizer(self.X, truncation=True, return_tensors=\"pt\")\n",
        "        # for I in range(999):\n",
        "        #     self.X_encoded.append(self.X_encoded[0])\n",
        "        # self.X_encoded = \n",
        "        # print(self.X_encoded.size())\n",
        "        # self.X_encoded = self.X_encoded.to(device)\n",
        "        print(\"Done Tokenizing.\")\n",
        "        self.input_ids = self.X_encoded['input_ids']\n",
        "        print(self.input_ids.size())\n",
        "        self.attention_mask = self.X_encoded['attention_mask']\n",
        "        '''\n",
        "            https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2Tokenizer\n",
        "            \n",
        "            1 for tokens that are not masked,\n",
        "            0 for tokens that are masked.\n",
        "        '''\n",
        "        # Mask the ground truth responses so the model can learn.\n",
        "        for i in range(len(self.X)):\n",
        "            res_i = (self.input_ids[i] == self.res_id).nonzero(as_tuple=True)[0]\n",
        "            self.attention_mask[i][res_i + 1:] = 0\n",
        "        #     # print(res_i)\n",
        "        #     # print(self.attention_mask[i].sum())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.input_ids[idx], self.attention_mask[idx])\n",
        "        # return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx]}\n",
        "        # return (self.X[idx])\n",
        "    def decode(self, tokens):\n",
        "        return self.tokenizer.decode(tokens)\n",
        "    \n",
        "    def decode_token(self, token_id):\n",
        "        return self.tokenizer.decoder.get(token_id)\n",
        "    \n",
        "    def decode_str(self, word):\n",
        "        return self.tokenizer.get_vocab()[word]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha0bwVTOYs2g"
      },
      "source": [
        "## Instantiate our Tokenizer, model, dataset, and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uy3EhuBYs2g",
        "outputId": "1d509037-f141-4bf8-fe0e-23b683517877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing Text...\n",
            "Done Tokenizing.\n",
            "torch.Size([100, 1024])\n"
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\", \n",
        "                                \"bos_token\": \"<BOS>\",\n",
        "                                \"eos_token\": \"<EOS>\"})\n",
        "tokenizer.add_tokens([\"<RES>:\"])\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# optim = Adam(model.parameters())\n",
        "\n",
        "ASCII_DATA = ASCIIDataset(\"./raw_data.json\", tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "rzFV4Hz_MBPj",
        "outputId": "32fecb07-e9bd-45d2-e603-1a300a28493c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<BOS> Apple emoji of grinning face <RES>:...........................................................\\n.....................%?????******?????%....................\\n................S???*****++;;;;;;++*****???S...............\\n.............S???**++;::,,,,,,,,,,,,::;;+**???%............\\n...........???**+;::,,,,,,,,,,,,,,,,,,,,,:;+**???..........\\n.........???**+::::::::,,,,,,,,,,,,,,::::::::;**???........\\n.......%??**+;:::::::::::::::::::::::::::::::::;**??S......\\n......???*+;::::::::::::::::::::::::::::::::::;:;+*???.....\\n.....??**+;;;;;;;;;;;::::::::::::::::::;;;;;;;;;;;+*???....\\n....%??*+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;+*??%...\\n...S??**+++++;;;;;;*%SS%+;;;;;;;;;;*%SS%+;;;;;;++++++*???..\\n...???*++++++++++;*#SSS#%+;;;;;;;;*##SS#S++++++++++++*??%..\\n..*%??**++++++++++*#SSSS%++++++++;*SSSSSS+++++++++++**??%?.\\n..????***++++++++++*%%%%+++++++++++*%%%%*++++++++++***??%%.\\n..%%??****+++++++++++++++++++++++++++++++++++++++++***??%%.\\n..%%??***+++++++++++++++++++++++++++++++++++++++++****??%%.\\n..?%???***+*?**++++++++++++++++++++++++++++++**?*+***???%%.\\n..*%???****%#%%S%%%???****************???%%%S%S#?****???%?.\\n...%%???***%S;;;++**?%%%%%%SSS%SS%%%%%%??*+++;*S****???%%..\\n...*%%???***S%;:::,,,,,,,,,,,,,,,,,,,,,,,,::;+S?***???%%?..\\n....?%%???***SS%??*++;::,,,,,,,,,,:::;++**?%%S%***???%%?...\\n.....?%%????**%SSSSSSSSS%%%%%%%%%%%SSSSSSSSSS?***???%%%....\\n......%%%????**?%SSSSSSSSSSSSSSSSSSSSSSSSSS%***????%%?.....\\n.......?%%%????**?%SSSSSSSSSSSSSSSSSSSSS%?***????%%%*......\\n.........%%%%?????**??%%SSSSSSSSSSSS%%?***?????%%%%........\\n...........%%%%??????***???????????****??????%%%%..........\\n.............?%%%%%???????????*??????????%%%%%%............\\n................%%%%%%%%%??????????%%%%%%%%%...............\\n.....................%%%%%%%%%%%%%%%%%%S................... <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ASCII_DATA)\n",
        "ASCII_DATA.decode(ASCII_DATA[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2peHmDSdFWI",
        "outputId": "2252c220-980c-4284-cd00-234844b68ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "354827264"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2znk2tqYs2h",
        "outputId": "de50dff6-5094-4b34-8b57-2590f9048bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1024])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "50260"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(ASCII_DATA[0][0].size())\n",
        "\n",
        "# for _ in (ASCII_DATA[0][1]):\n",
        "#     print(_)\n",
        "ASCII_DATA.decode_str(\"<RES>:\")\n",
        "# ASCII_DATA[0]['input_ids'].size()\n",
        "# for _ in range(5):\n",
        "#     print(ASCII_DATA[_][0][:10])\n",
        "#     print(ASCII_DATA[_][1][:20])\n",
        "#     print(\"\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "az5VcPOfYs2h"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(ASCII_DATA, batch_size=4) # can be changed to the number of available cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "423yXWW5Ys2h"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, dataloader):\n",
        " \n",
        "    e = 1\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for _ in tqdm.tqdm(range(e)):\n",
        "\n",
        "        for b_ids, b_masks in dataloader:\n",
        "            \n",
        "\n",
        "            b_ids = b_ids.to(device)\n",
        "            b_masks = b_masks.to(device)\n",
        "            b_labels = b_ids\n",
        "\n",
        "            # print(b_ids.size(), b_masks.size(), b_labels.size())\n",
        "\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "            out = model(input_ids=b_ids, \n",
        "                         labels=b_labels,\n",
        "                         attention_mask=b_masks)\n",
        "            \n",
        "            loss = out.loss\n",
        "            # print('poo')\n",
        "            # print(loss.loss)\n",
        "            # test = loss.loss()\n",
        "            # print('poo')\n",
        "            \n",
        "            print(f'current loss: {loss}')\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "\n",
        "        torch.save(model.state_dict(), f\"model_state_{_}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yYxXL0zTYs2i"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "    The JSON input should be of the same form that is passed to the dataloader.\n",
        "\n",
        "    {\n",
        "        \"prompt: \"...\",\n",
        "        \"text\": \"...\"\n",
        "    }\n",
        "'''\n",
        "\n",
        "def prompt(prompt):\n",
        "\n",
        "    # prompt = json_input['prompt']\n",
        "    # text = \"\"\n",
        "    # inp = f'<BOS> {prompt}\\n<RES>:\\n{tbext}\\n<EOS>'\n",
        "    inp = f'<BOS> {prompt}\\n<RES>:\\n'\n",
        "    print(inp)\n",
        "    # inp = tokenizer(inp, return_tensors=\"pt\")\n",
        "    # inp = tokenizer(inp, max_new_tokens=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    inp = tokenizer(prompt, return_tensors='pt')\n",
        "    # print(inp.size())\n",
        "    x = inp[\"input_ids\"].to(device)\n",
        "    a = inp[\"attention_mask\"].to(device)\n",
        "    # print(a)\n",
        "\n",
        "    # res_i = (x == 50260).nonzero(as_tuple=True)[0]\n",
        "    # a[res_i + 1:] = 0\n",
        "\n",
        "    pad_token = ASCII_DATA.decode_str(\"<pad>\")\n",
        "    # eos_token = ASCII_DATA.decode_str(\"<pad>\")\n",
        "\n",
        "    output = model.generate(x, attention_mask=a, pad_token_id=pad_token, max_length=1024)\n",
        "    output = tokenizer.decode(output[0])\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "dupxvtMyFNX3",
        "outputId": "701fc7f8-e0fb-493a-d8ed-4b719bbb6cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BOS> Apple emoji of grinning face\n",
            "<RES>:\n",
            "\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "The operator 'aten::cumsum.out' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/danielcufino/Desktop/S23/COMP 646/project/Text2ASCII_C.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prompt(\u001b[39m'\u001b[39;49m\u001b[39mApple emoji of grinning face\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "\u001b[1;32m/Users/danielcufino/Desktop/S23/COMP 646/project/Text2ASCII_C.ipynb Cell 17\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m pad_token \u001b[39m=\u001b[39m ASCII_DATA\u001b[39m.\u001b[39mdecode_str(\u001b[39m\"\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# eos_token = ASCII_DATA.decode_str(\"<pad>\")\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(x, attention_mask\u001b[39m=\u001b[39;49ma, pad_token_id\u001b[39m=\u001b[39;49mpad_token, max_length\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m output \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/generation_utils.py:1490\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1486\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1487\u001b[0m         )\n\u001b[1;32m   1489\u001b[0m     \u001b[39m# 10. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1490\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1491\u001b[0m         input_ids,\n\u001b[1;32m   1492\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1493\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1494\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1495\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1496\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1497\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1498\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1499\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1500\u001b[0m     )\n\u001b[1;32m   1502\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1504\u001b[0m     \u001b[39mif\u001b[39;00m num_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/generation_utils.py:2230\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m \u001b[39m# prepare model inputs\u001b[39;00m\n\u001b[0;32m-> 2230\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m   2232\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\n\u001b[1;32m   2234\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[1;32m   2235\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2236\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   2237\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   2238\u001b[0m )\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:999\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.prepare_inputs_for_generation\u001b[0;34m(self, input_ids, past, **kwargs)\u001b[0m\n\u001b[1;32m    995\u001b[0m position_ids \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mposition_ids\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    997\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m position_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    998\u001b[0m     \u001b[39m# create position_ids on the fly for batch generation\u001b[39;00m\n\u001b[0;32m--> 999\u001b[0m     position_ids \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39;49mlong()\u001b[39m.\u001b[39;49mcumsum(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1000\u001b[0m     position_ids\u001b[39m.\u001b[39mmasked_fill_(attention_mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m   1001\u001b[0m     \u001b[39mif\u001b[39;00m past:\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::cumsum.out' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
          ]
        }
      ],
      "source": [
        "prompt('Apple emoji of grinning face')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "woAWtej4Ys2i"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 3e-5\n",
        "WARMUP_STEPS = 5000\n",
        "MAX_SEQ_LEN = 1024\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "# scheduler = WarmupLinearSchedule(optimizer, warmup_steps=WARMUP_STEPS, t_total = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-hSe3FpYs2i",
        "outputId": "6dda3edc-bdd6-4097-9114-9df6bce83241"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "tensors must be 2-D",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/Users/danielcufino/Desktop/S23/COMP 646/project/Text2ASCII_C.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(model, optim, dataloader)\n",
            "\u001b[1;32m/Users/danielcufino/Desktop/S23/COMP 646/project/Text2ASCII_C.ipynb Cell 19\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, dataloader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# print(b_ids.size(), b_masks.size(), b_labels.size())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m out \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49mb_ids, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m              labels\u001b[39m=\u001b[39;49mb_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m              attention_mask\u001b[39m=\u001b[39;49mb_masks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# print('poo')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# print(loss.loss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# test = loss.loss()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielcufino/Desktop/S23/COMP%20646/project/Text2ASCII_C.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# print('poo')\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1046\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1046\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   1047\u001b[0m     input_ids,\n\u001b[1;32m   1048\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1049\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1050\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1051\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1052\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1053\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1054\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1055\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1056\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1057\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1058\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1059\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1060\u001b[0m )\n\u001b[1;32m   1061\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1063\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:889\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    879\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    880\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    881\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    890\u001b[0m         hidden_states,\n\u001b[1;32m    891\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    892\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    893\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    894\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    895\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    896\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    897\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    898\u001b[0m     )\n\u001b[1;32m    900\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    901\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:389\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    388\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 389\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    390\u001b[0m     hidden_states,\n\u001b[1;32m    391\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    392\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    393\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    394\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    395\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    396\u001b[0m )\n\u001b[1;32m    397\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:311\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    309\u001b[0m     attention_mask \u001b[39m=\u001b[39m encoder_attention_mask\n\u001b[1;32m    310\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     query, key, value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc_attn(hidden_states)\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_size, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    313\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_heads(query, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[1;32m    314\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_heads(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/transformers/pytorch_utils.py:112\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    111\u001b[0m     size_out \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnf,)\n\u001b[0;32m--> 112\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[1;32m    113\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(size_out)\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tensors must be 2-D"
          ]
        }
      ],
      "source": [
        "train(model, optim, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDkFfUA-Ys2i"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7eUPPBJHESe",
        "outputId": "41ef1a26-488f-4fdd-a215-3c630f033617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BOS> Apple emoji of grinning face\n",
            "<RES>:\n",
            "\n",
            "Apple emoji of grinning face <pad> @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@@@\n",
            "@@@@@@@@+++************+++@@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "@@@@@@@@+++************+++@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@+++************+++@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@+++************+++@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@\n",
            "@@@@@@@@:@@@@@@@+++??%%%%%%??***+++@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@+++**?%SS#########S%?**++@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@++**%S#########S?**++@@@@@@@@@@@@\n",
            "@@@@@@@@@@@@@\n",
            "@@@@@@@@:++**%S###############S?**++*@@@@@@@@@@\n",
            "@@@@@@@@:++*?S#################S%?*++*?S?*++*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?*?\n"
          ]
        }
      ],
      "source": [
        "print(prompt(\"Apple emoji of grinning face\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "n1fo9t_EQXyt"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './test.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbf2nyFERBaU",
        "outputId": "47382649-f884-41fa-8108-b0a37f7e01b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./tokenizer/tokenizer_config.json',\n",
              " './tokenizer/special_tokens_map.json',\n",
              " './tokenizer/vocab.json',\n",
              " './tokenizer/merges.txt',\n",
              " './tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained('./tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NaAclUaHOuCz",
        "outputId": "f2f5396b-fcfc-41c5-9cd4-fdc549e1bf43"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6e43475f4f48>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii-gen'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./test.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./tokenizer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m             )\n\u001b[1;32m    731\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mnormalized_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mpipeline_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"impl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPIPELINE_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid translation task {task}, use 'translation_XX_to_YY' format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m         raise KeyError(\n\u001b[0m\u001b[1;32m   1185\u001b[0m             \u001b[0;34mf\"Unknown task {task}, available tasks are {self.get_supported_tasks() + ['translation_XX_to_YY']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         )\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Unknown task ascii-gen, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\""
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "chef = pipeline('ascii-gen',model='./test.pt', tokenizer='./tokenizer',config={'max_length':1024})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "<BOS> Apple emoji of grinning face <RES>:...........................................................\n",
        ".....................%?????******?????%....................\n",
        "................S???*****++;;;;;;++*****???S...............\n",
        ".............S???**++;::,,,,,,,,,,,,::;;+**???%............\n",
        "...........???**+;::,,,,,,,,,,,,,,,,,,,,,:;+**???..........\n",
        ".........???**+::::::::,,,,,,,,,,,,,,::::::::;**???........\n",
        ".......%??**+;:::::::::::::::::::::::::::::::::;**??S......\n",
        "......???*+;::::::::::::::::::::::::::::::::::;:;+*???.....\n",
        ".....??**+;;;;;;;;;;;::::::::::::::::::;;;;;;;;;;;+*???....\n",
        "....%??*+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;+*??%...\n",
        "...S??**+++++;;;;;;*%SS%+;;;;;;;;;;*%SS%+;;;;;;++++++*???..\n",
        "...???*++++++++++;*#SSS#%+;;;;;;;;*##SS#S++++++++++++*??%..\n",
        "..*%??**++++++++++*#SSSS%++++++++;*SSSSSS+++++++++++**??%?.\n",
        "..????***++++++++++*%%%%+++++++++++*%%%%*++++++++++***??%%.\n",
        "..%%??****+++++++++++++++++++++++++++++++++++++++++***??%%.\n",
        "..%%??***+++++++++++++++++++++++++++++++++++++++++****??%%.\n",
        "..?%???***+*?**++++++++++++++++++++++++++++++**?*+***???%%.\n",
        "..*%???****%#%%S%%%???****************???%%%S%S#?****???%?.\n",
        "...%%???***%S;;;++**?%%%%%%SSS%SS%%%%%%??*+++;*S****???%%..\n",
        "...*%%???***S%;:::,,,,,,,,,,,,,,,,,,,,,,,,::;+S?***???%%?..\n",
        "....?%%???***SS%??*++;::,,,,,,,,,,:::;++**?%%S%***???%%?...\n",
        ".....?%%????**%SSSSSSSSS%%%%%%%%%%%SSSSSSSSSS?***???%%%....\n",
        "......%%%????**?%SSSSSSSSSSSSSSSSSSSSSSSSSS%***????%%?.....\n",
        ".......?%%%????**?%SSSSSSSSSSSSSSSSSSSSS%?***????%%%*......\n",
        ".........%%%%?????**??%%SSSSSSSSSSSS%%?***?????%%%%........\n",
        "...........%%%%??????***???????????****??????%%%%..........\n",
        ".............?%%%%%???????????*??????????%%%%%%............\n",
        "................%%%%%%%%%??????????%%%%%%%%%...............\n",
        ".....................%%%%%%%%%%%%%%%%%%S................... <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "<BOS> Please generate ASCII art of an emoji of grinning face <RES>: %?????******?????%                    \n",
        "                S???*****++;;;;;;++*****???S               \n",
        "             S???**++;::............::;;+**???%            \n",
        "          ???**+;::.....................:;+**???          \n",
        "        ???**+::::::::..............::::::::;**???        \n",
        "       %??**+;:::::::::::::::::::::::::::::::::;**??S      \n",
        "     ???*+;::::::::::::::::::::::::::::::::::;:;+*???     \n",
        "    ??**+;;;;;;;;;;;::::::::::::::::::;;;;;;;;;;;+*???    \n",
        "    %??*+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;+*??%   \n",
        "   S??**+++++;;;;;;*%SS%+;;;;;;;;;;*%SS%+;;;;;;++++++*???  \n",
        "  ???*++++++++++;*#SSS#%+;;;;;;;;*##SS#S++++++++++++*??%  \n",
        "  *%??**++++++++++*#SSSS%++++++++;*SSSSSS+++++++++++**??%? \n",
        " ????***++++++++++*%%%%+++++++++++*%%%%*++++++++++***??%% \n",
        "  %%??****+++++++++++++++++++++++++++++++++++++++++***??%% \n",
        "  %%??***+++++++++++++++++++++++++++++++++++++++++****??%% \n",
        " ?%???***+*?**++++++++++++++++++++++++++++++**?*+***???%% \n",
        "  *%???****%#%%S%%%???****************???%%%S%S#?****???%? \n",
        "   %%???***%S;;;++**?%%%%%%SSS%SS%%%%%%??*+++;*S****???%%  \n",
        "   *%%???***S%;:::........................::;+S?***???%%?  \n",
        "   ?%%???***SS%??*++;::..........:::;++**?%%S%***???%%?   \n",
        "    ?%%????**%SSSSSSSSS%%%%%%%%%%%SSSSSSSSSS?***???%%%    \n",
        "      %%%????**?%SSSSSSSSSSSSSSSSSSSSSSSSSS%***????%%?     \n",
        "      ?%%%????**?%SSSSSSSSSSSSSSSSSSSSS%?***????%%%*      \n",
        "         %%%%?????**??%%SSSSSSSSSSSS%%?***?????%%%%        \n",
        "           %%%%??????***???????????****??????%%%%          \n",
        "            ?%%%%%???????????*??????????%%%%%%            \n",
        "                %%%%%%%%%??????????%%%%%%%%%               \n",
        "                     %%%%%%%%%%%%%%%%%%S <EOS>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
